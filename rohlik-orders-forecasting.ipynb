{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":80874,"databundleVersionId":8794587,"sourceType":"competition"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-02T11:13:23.795815Z","iopub.execute_input":"2024-08-02T11:13:23.796663Z","iopub.status.idle":"2024-08-02T11:13:23.803656Z","shell.execute_reply.started":"2024-08-02T11:13:23.796622Z","shell.execute_reply":"2024-08-02T11:13:23.802719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install calmap","metadata":{"execution":{"iopub.status.busy":"2024-08-02T11:16:29.766206Z","iopub.execute_input":"2024-08-02T11:16:29.767104Z","iopub.status.idle":"2024-08-02T11:16:43.074468Z","shell.execute_reply.started":"2024-08-02T11:16:29.767071Z","shell.execute_reply":"2024-08-02T11:16:43.073323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport scipy.stats as stats\nimport math\nimport statsmodels.api as sm\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\nfrom prettytable import PrettyTable\nfrom tqdm import tqdm\nfrom statsmodels.tsa.stattools import adfuller\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T13:29:46.052771Z","iopub.execute_input":"2024-08-02T13:29:46.053711Z","iopub.status.idle":"2024-08-02T13:29:46.059884Z","shell.execute_reply.started":"2024-08-02T13:29:46.053680Z","shell.execute_reply":"2024-08-02T13:29:46.058731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/rohlik-orders-forecasting-challenge/train.csv')\ntest = pd.read_csv('/kaggle/input/rohlik-orders-forecasting-challenge/test.csv')\ntrain_calendar = pd.read_csv('/kaggle/input/rohlik-orders-forecasting-challenge/train_calendar.csv')\ntest_calendar = pd.read_csv('/kaggle/input/rohlik-orders-forecasting-challenge/test_calendar.csv')\nsubmission = pd.read_csv('/kaggle/input/rohlik-orders-forecasting-challenge/solution_example.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-02T11:13:26.085117Z","iopub.execute_input":"2024-08-02T11:13:26.085425Z","iopub.status.idle":"2024-08-02T11:13:26.198137Z","shell.execute_reply.started":"2024-08-02T11:13:26.085401Z","shell.execute_reply":"2024-08-02T11:13:26.197420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv_datetime(dfs, date_column = 'date'):\n    for df in dfs:\n        df[date_column] = pd.to_datetime(df[date_column])","metadata":{"execution":{"iopub.status.busy":"2024-08-02T11:13:39.886738Z","iopub.execute_input":"2024-08-02T11:13:39.887085Z","iopub.status.idle":"2024-08-02T11:13:39.891780Z","shell.execute_reply.started":"2024-08-02T11:13:39.887056Z","shell.execute_reply":"2024-08-02T11:13:39.890719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_datetime([train,test,train_calendar,test_calendar])\ntrain.drop(columns = ['id'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T11:14:28.775756Z","iopub.execute_input":"2024-08-02T11:14:28.776431Z","iopub.status.idle":"2024-08-02T11:14:28.803055Z","shell.execute_reply.started":"2024-08-02T11:14:28.776400Z","shell.execute_reply":"2024-08-02T11:14:28.802178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This notebook aims to analyze the data provided for the **Rohlik Orders Forecasting Challenge**. The task is to predict the number of orders at selected warehouses for the next 60 days. The models will be evaluated on MAPE (mean absolute percentage erro) between predicted and actual orders. \n\nBased in Prague, the Rohlik Group is a European technology leader in e-grocery, with presence in several cities. Below, is a brief timeline of the company:\n* **2015**: Expansion to Brno\n* **2019**: Expansion to Budapest\n* **2020**: Expansion to Austria\n* **2021**: Expansion to Munich\n* **2022**: Expansion to Frankfurt\n\n**Warehouse available for the competition**: Prague_1, Prague_2, Prague_3, Brno_1, Frankfurt_1, Munich_1, Budapest_1 ","metadata":{}},{"cell_type":"markdown","source":"## 1. INTRODUCTION","metadata":{}},{"cell_type":"markdown","source":"We have 5 files available:\n\n* **train**: historical orders and selected features for each warehouse. The data is in daily frequence.\n* **test**: \"future\" data that will be forecasted.\n* **train_calendar**: a calendar for each warehouse for the train period.\n* **test_calendar**: a calendar for each warehouse for the test period.\n* **solution_example**: the submission format for this competition.","metadata":{}},{"cell_type":"code","source":"train.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T11:35:46.355720Z","iopub.execute_input":"2024-08-02T11:35:46.356729Z","iopub.status.idle":"2024-08-02T11:35:46.381292Z","shell.execute_reply.started":"2024-08-02T11:35:46.356682Z","shell.execute_reply":"2024-08-02T11:35:46.380431Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T11:36:35.955985Z","iopub.execute_input":"2024-08-02T11:36:35.956448Z","iopub.status.idle":"2024-08-02T11:36:35.967701Z","shell.execute_reply.started":"2024-08-02T11:36:35.956414Z","shell.execute_reply":"2024-08-02T11:36:35.966779Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Train data has {train.shape[0]} rows and {train.shape[1]} columns.\")\nprint(f\"Test data has {test.shape[0]} rows and {test.shape[1]} columns.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-02T11:38:54.645832Z","iopub.execute_input":"2024-08-02T11:38:54.646197Z","iopub.status.idle":"2024-08-02T11:38:54.651377Z","shell.execute_reply.started":"2024-08-02T11:38:54.646156Z","shell.execute_reply":"2024-08-02T11:38:54.650400Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#missing values\ntrain.isnull().sum() / len(train) * 100","metadata":{"execution":{"iopub.status.busy":"2024-08-02T11:39:42.376228Z","iopub.execute_input":"2024-08-02T11:39:42.376795Z","iopub.status.idle":"2024-08-02T11:39:42.389128Z","shell.execute_reply.started":"2024-08-02T11:39:42.376754Z","shell.execute_reply":"2024-08-02T11:39:42.388390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notes:\n\n* Not all features in train set are present in test set.\n* holiday_name is NaN when a given day is not a holiday or when holiday name was not registered. Holiday_name = NaN does not gurantee that a given day is not a holiday.\n* Precipitation, snow and user activity could be forecasted alongside the target orders. ","metadata":{}},{"cell_type":"code","source":"train['year'] = train['date'].dt.year\ntrain['weekday'] = train['date'].dt.weekday\ntrain['dayofyear'] = train['date'].dt.dayofyear\ntrain['daynum'] = (train.date - train.date.iloc[0]).dt.days\ntrain['weeknum'] = train['daynum'] // 7\ntrain['month'] = train['date'].dt.to_period('M')\ntrain['month_n'] = train['date'].dt.month\ntrain['day'] = train['date'].dt.day","metadata":{"execution":{"iopub.status.busy":"2024-08-02T11:49:13.495937Z","iopub.execute_input":"2024-08-02T11:49:13.496302Z","iopub.status.idle":"2024-08-02T11:49:13.511984Z","shell.execute_reply.started":"2024-08-02T11:49:13.496272Z","shell.execute_reply":"2024-08-02T11:49:13.510989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Range of Time Series","metadata":{}},{"cell_type":"code","source":"row_counts_df = train.groupby(['warehouse']).size().reset_index(name='Entries')\ndates_df = train.groupby(['warehouse'])['date'].agg(['min','max']).reset_index()\ndates_df.columns = ['warehouse','Earliest_entry','Latest_entry']\ntrain_summ = pd.merge(row_counts_df,dates_df, on = ['warehouse'])\ntrain_summ","metadata":{"execution":{"iopub.status.busy":"2024-08-02T11:52:19.574817Z","iopub.execute_input":"2024-08-02T11:52:19.575797Z","iopub.status.idle":"2024-08-02T11:52:19.600996Z","shell.execute_reply.started":"2024-08-02T11:52:19.575761Z","shell.execute_reply":"2024-08-02T11:52:19.600098Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row_counts_df_test = test.groupby(['warehouse']).size().reset_index(name='Entries')\ndates_df_test = test.groupby(['warehouse'])['date'].agg(['min','max']).reset_index()\ndates_df_test.columns = ['warehouse','Earliest_entry','Latest_entry']\ntest_summ = pd.merge(row_counts_df_test,dates_df_test, on = ['warehouse'])\ntest_summ","metadata":{"execution":{"iopub.status.busy":"2024-08-02T11:53:44.137284Z","iopub.execute_input":"2024-08-02T11:53:44.138139Z","iopub.status.idle":"2024-08-02T11:53:44.155593Z","shell.execute_reply.started":"2024-08-02T11:53:44.138109Z","shell.execute_reply":"2024-08-02T11:53:44.154615Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_consecutive_rows(df):\n    \n    res = {}\n    \n    for warehouse in df['warehouse'].unique():\n        warehouse_df = df[df['warehouse']==warehouse].sort_values('date')\n        comp_range = pd.date_range(start=warehouse_df['date'].min(), end=warehouse_df['date'].max())\n        actual = warehouse_df['date'].tolist()\n        missing = [date for date in comp_range if date not in actual]\n        \n        res[warehouse] = {\n            'is_consecutive': len(missing)==0,\n            'missing_dates': missing,\n            'missing_count': len(missing)\n        }\n        \n    return res\n\nresults = check_consecutive_rows(train)\n\nfor warehouse,result in results.items():\n    print(f\"Warehouse: {warehouse}\")\n    if(result['is_consecutive']):\n        print(f\"  Status: Consecutive\")\n    else:\n        print(f\"  Status: Not Consecutive\")\n        print(f\"  Total missing days: {result['missing_count']}\")\n        print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:08:33.678594Z","iopub.execute_input":"2024-08-02T12:08:33.678953Z","iopub.status.idle":"2024-08-02T12:08:34.093237Z","shell.execute_reply.started":"2024-08-02T12:08:33.678923Z","shell.execute_reply":"2024-08-02T12:08:34.092330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.3 Common features","metadata":{}},{"cell_type":"code","source":"group_df = train.groupby(['warehouse', 'month_n'])[['holiday','shops_closed','winter_school_holidays','school_holidays']].sum().reset_index()\nwarehouses = train['warehouse'].unique()\n\nfig, axs = plt.subplots(nrows=(len(warehouses) // 3)+1,ncols=3,figsize=(16,12))\naxs = axs.flatten()\n\nfor i, warehouse in enumerate(warehouses):\n    data = group_df[group_df['warehouse'] == warehouse].set_index('month_n')\n    data = data[['holiday','shops_closed','winter_school_holidays','school_holidays']]\n    data.plot(kind='bar', stacked=True,ax=axs[i])\n    \n    axs[i].set_title(f\"{warehouse}\", fontsize=18)\n    axs[i].set_xlabel('')\n    axs[i].set_ylabel('')\n    axs[i].legend(fontsize=14)\n    axs[i].tick_params(axis='x', rotation=0)\n    \nfor j in range(i+1, len(axs)):\n    fig.delaxes(axs[j])\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:20:15.623627Z","iopub.execute_input":"2024-08-02T12:20:15.624034Z","iopub.status.idle":"2024-08-02T12:20:18.161264Z","shell.execute_reply.started":"2024-08-02T12:20:15.623995Z","shell.execute_reply":"2024-08-02T12:20:18.160434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Time Series Overview","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,8))\n\nfor i, warehouse in enumerate(warehouses):\n    df_warehouses = train[train['warehouse'] == warehouse]\n    sns.lineplot(x='date',y='orders',data=df_warehouses, label=warehouse)\n\nplt.title('Orders Over Time', fontsize=18)\nplt.legend(fontsize=16)\nplt.xticks(rotation=0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:41:35.413732Z","iopub.execute_input":"2024-08-02T12:41:35.414542Z","iopub.status.idle":"2024-08-02T12:41:36.142645Z","shell.execute_reply.started":"2024-08-02T12:41:35.414510Z","shell.execute_reply":"2024-08-02T12:41:36.141754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clear seasonal patterns for every warehouse.\n\n* Prague, Brno, and Budapest seem to have a yearly seasonal pattern, with the peak in late December. These operations were all well-established when the historical data started being recorded, which is probably why we see a clear pattern for these locations.\n","metadata":{}},{"cell_type":"code","source":"train.sort_values(['warehouse','date'], inplace=True)\n\nfor warehouse in warehouses:\n    df_warehouse = train[train['warehouse']==warehouse]\n    plt.figure(figsize=(12,5))\n    plt.plot(df_warehouse['date'],df_warehouse['orders'],marker='',linestyle='-')\n    plt.title(f\"Orders over time for {warehouse}\", fontsize=16)\n    plt.xticks(rotation=45)\n    \n    ax=plt.gca()\n    \n        # Highlight school holiday periods\n    school_holiday_periods = df_warehouse['school_holidays'] == 1\n    school_holiday_start_end = (school_holiday_periods != school_holiday_periods.shift()).cumsum()\n    \n    for period in school_holiday_start_end.unique():\n        if school_holiday_periods[school_holiday_start_end == period].any():\n            school_holiday_period = df_warehouse[school_holiday_start_end == period]\n            start = school_holiday_period['date'].min()\n            end = school_holiday_period['date'].max()\n            ax.axvspan(start, end, color='red', alpha=0.2)\n    \n    # Highlight winter school holiday periods\n    winter_holiday_periods = df_warehouse['winter_school_holidays'] == 1\n    winter_holiday_start_end = (winter_holiday_periods != winter_holiday_periods.shift()).cumsum()\n    \n    for period in winter_holiday_start_end.unique():\n        if winter_holiday_periods[winter_holiday_start_end == period].any():\n            winter_holiday_period = df_warehouse[winter_holiday_start_end == period]\n            winter_start = winter_holiday_period['date'].min()\n            winter_end = winter_holiday_period['date'].max()\n            ax.axvspan(winter_start, winter_end, color='green', alpha=0.2)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T13:05:12.196293Z","iopub.execute_input":"2024-08-02T13:05:12.197041Z","iopub.status.idle":"2024-08-02T13:05:14.721999Z","shell.execute_reply.started":"2024-08-02T13:05:12.197009Z","shell.execute_reply":"2024-08-02T13:05:14.721108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.1 Moving Average","metadata":{}},{"cell_type":"code","source":"for warehouse in warehouses:\n    df_warehouse = train[train['warehouse'] == warehouse]\n    df_warehouse = df_warehouse.copy()\n\n    plt.figure(figsize=(12, 5))\n    \n    # original time series\n    plt.plot(df_warehouse['date'], df_warehouse['orders'], marker='', linestyle='-', label='Original', alpha=0.5)\n    \n    # 7-day moving average\n    df_warehouse.loc[:,'7_day_ma'] = df_warehouse['orders'].rolling(window=7).mean()\n    plt.plot(df_warehouse['date'], df_warehouse['7_day_ma'], marker='', linestyle='-', color='red', label='7 Day Moving Average')\n    \n    # 30-day moving average\n    df_warehouse.loc[:,'30_day_ma'] = df_warehouse['orders'].rolling(window=30).mean()\n    plt.plot(df_warehouse['date'], df_warehouse['30_day_ma'], marker='', linestyle='-', color='green', label='30 Day Moving Average')\n        \n    plt.title(f'Orders over Time for {warehouse}', fontsize=16)\n    plt.xticks(rotation=0)\n    plt.legend(fontsize=14)\n\n    \nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-02T13:10:49.870804Z","iopub.execute_input":"2024-08-02T13:10:49.871492Z","iopub.status.idle":"2024-08-02T13:10:52.805151Z","shell.execute_reply.started":"2024-08-02T13:10:49.871456Z","shell.execute_reply":"2024-08-02T13:10:52.804250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2 Weekdays","metadata":{}},{"cell_type":"code","source":"selected_warehouses = ['Prague_1', 'Prague_2', 'Prague_3', 'Brno_1', 'Budapest_1',\n                      'Frankfurt_1', 'Munich_1']\n\n# Group by week number, warehouse, and weekday\norders_per_week_warehouse_weekday = train.groupby(['weeknum', 'warehouse', 'weekday'])['orders'].sum().reset_index().pivot(index=['weeknum', 'warehouse'], columns='weekday')\n\n# Fill NaN values with 0\norders_per_week_warehouse_weekday = orders_per_week_warehouse_weekday.fillna(0)\n\n# Calculate the ratio of orders per weekday for each week and warehouse\nratio_orders_per_week_warehouse_weekday = orders_per_week_warehouse_weekday.apply(lambda row: row/sum(row) if sum(row) != 0 else row, axis=1).reset_index()\n\n# Initialize an empty DataFrame to store median ratios\nratio_weekday = pd.DataFrame(columns=selected_warehouses, index=range(7), data=[[0, ]*len(selected_warehouses)]*7)\n\n# Create subplots for each selected warehouse\nfig, ax = plt.subplots(nrows=len(selected_warehouses), figsize=(24, 5*len(selected_warehouses)))\n\n# Loop through each selected warehouse and plot the ratios\nfor n, warehouse in enumerate(selected_warehouses):\n    for d in range(7):\n        dt = ratio_orders_per_week_warehouse_weekday.loc[ratio_orders_per_week_warehouse_weekday.warehouse == warehouse, ('orders', d)]\n        dt = dt[15:-15]  # Exclude the first and last 15 values\n        ratio_weekday.loc[d, warehouse] = dt.median()\n        ax[n].plot(range(len(dt)), dt, label=f'Day {d}', linewidth=3)\n        \n    ax[n].set_title(warehouse, fontsize=20)\n    ax[n].legend(fontsize=18)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T13:14:52.929873Z","iopub.execute_input":"2024-08-02T13:14:52.930746Z","iopub.status.idle":"2024-08-02T13:14:55.586278Z","shell.execute_reply.started":"2024-08-02T13:14:52.930712Z","shell.execute_reply":"2024-08-02T13:14:55.585274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notes:\n\n* Frankfurt and Munich warehouses do not open on Sundays, that's why we see a constant line on zero.\n* Suddently drops to zero means that the warehouse was closed on that day.\n* Friday (Day 4) seems to be the best day of the week","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\n\nratio_weekday_mean = ratio_weekday.mean(axis=1)\nratio_weekday['mean'] = ratio_weekday_mean\n\nratio_weekday.style.bar(subset=['mean'], color=px.colors.qualitative.Set2[7])\\\n        .background_gradient(subset=['Prague_1'], cmap='BuGn')\\\n        .background_gradient(subset=['Prague_2'], cmap='BuGn')\\\n        .background_gradient(subset=['Prague_3'], cmap='BuGn')\\\n        .background_gradient(subset=['Brno_1'], cmap='BuGn')\\\n        .background_gradient(subset=['Budapest_1'], cmap='BuGn')\\\n        .background_gradient(subset=['Frankfurt_1'], cmap='BuGn_r')\\\n        .background_gradient(subset=['Munich_1'], cmap='BuGn_r')","metadata":{"execution":{"iopub.status.busy":"2024-08-02T13:19:03.206948Z","iopub.execute_input":"2024-08-02T13:19:03.207892Z","iopub.status.idle":"2024-08-02T13:19:03.883770Z","shell.execute_reply.started":"2024-08-02T13:19:03.207851Z","shell.execute_reply":"2024-08-02T13:19:03.882706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.3 Seasonal Plots","metadata":{}},{"cell_type":"code","source":"\ndef seasonal_plot(X, y, period, freq, ax=None):\n    if ax is None:\n        _, ax = plt.subplots()\n    ax = sns.lineplot(\n        x=freq,\n        y=y,\n        hue=period,\n        data=X,\n        ci=False,\n        ax=ax,\n        legend=False,\n    )\n    ax.set_title(f\"Seasonal Plot ({period}/{freq})\")\n    for line, name in zip(ax.lines, X[period].unique()):\n        y_ = line.get_ydata()[-1]\n        ax.annotate(\n            name,\n            xy=(1, y_),\n            xytext=(6, 0),\n            color=line.get_color(),\n            xycoords=ax.get_yaxis_transform(),\n            textcoords=\"offset points\",\n            size=14,\n            va=\"center\",\n        )\n    return ax\n\nfig, axes = plt.subplots(len(warehouses), 1, figsize=(11, 6 * len(warehouses)), sharex=True)\n\nfor warehouse, ax in zip(warehouses, axes):\n    warehouse_data = train[train['warehouse'] == warehouse]\n    seasonal_plot(warehouse_data, y=\"orders\", period=\"year\", freq=\"dayofyear\", ax=ax)\n    ax.set_title(f\"Seasonal Plot for {warehouse} (year/dayofyear)\")\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T13:20:54.668224Z","iopub.execute_input":"2024-08-02T13:20:54.669250Z","iopub.status.idle":"2024-08-02T13:20:57.353163Z","shell.execute_reply.started":"2024-08-02T13:20:54.669216Z","shell.execute_reply":"2024-08-02T13:20:57.352103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notes:\n\n* Munich and Frankfurt operations are completely different from the other warehouses, and they also show a clearly stronger performance in 2024 compared to previous years.\n* Budapest, Brno, and Prague all have their worst month in July.\n* All warehouses show both weekly and yearly seasonality.","metadata":{}},{"cell_type":"markdown","source":"## 2.4 Autocorrelation Analysis","metadata":{}},{"cell_type":"markdown","source":"ACF measures the linear relationship between lagged values of a time series\n\nPACF measures the correlation between lagged values in a time series when we remove the influence of correlated lagged values in between.","metadata":{}},{"cell_type":"code","source":"\nbrno_data = train[train['warehouse'] == 'Brno_1']\nbrno_data = brno_data[brno_data['year'] != 2020]\nbrno_data.reset_index(drop=True, inplace=True)\nbrno_data = brno_data[['date', 'orders']]\nbrno_data.set_index('date', inplace=True)\nbrno_data = brno_data.asfreq('D')\nbrno_data.fillna(method='ffill', inplace=True)\n\npr1_data = train[train['warehouse'] == 'Prague_1']\npr1_data = pr1_data[pr1_data['year'] != 2020]\npr1_data.reset_index(drop=True, inplace=True)\npr1_data = pr1_data[['date', 'orders']]\npr1_data.set_index('date', inplace=True)\npr1_data = pr1_data.asfreq('D')\npr1_data.fillna(method='ffill', inplace=True)\n\npr2_data = train[train['warehouse'] == 'Prague_2']\npr2_data = pr2_data[pr2_data['year'] != 2020]\npr2_data.reset_index(drop=True, inplace=True)\npr2_data = pr2_data[['date', 'orders']]\npr2_data.set_index('date', inplace=True)\npr2_data = pr2_data.asfreq('D')\npr2_data.fillna(method='ffill', inplace=True)\n\npr3_data = train[train['warehouse'] == 'Prague_3']\npr3_data = pr3_data[pr3_data['year'] != 2020]\npr3_data.reset_index(drop=True, inplace=True)\npr3_data = pr3_data[['date', 'orders']]\npr3_data.set_index('date', inplace=True)\npr3_data = pr3_data.asfreq('D')\npr3_data.fillna(method='ffill', inplace=True)\n\nbdp_data = train[train['warehouse'] == 'Budapest_1']\nbdp_data = bdp_data[bdp_data['year'] != 2020]\nbdp_data = bdp_data[bdp_data['year'] != 2021]\nbdp_data = bdp_data[bdp_data['date'] != '2024-03-14']\nbdp_data.reset_index(drop=True, inplace=True)\nbdp_data = bdp_data[['date', 'orders']]\nbdp_data.set_index('date', inplace=True)\nbdp_data = bdp_data.asfreq('D')\nbdp_data.fillna(method='ffill', inplace=True)\n\nmunich_data = train[train['warehouse'] == 'Munich_1']\nmunich_data = munich_data[munich_data['year'] != 2021]\nmunich_data.reset_index(drop=True, inplace=True)\nmunich_data = munich_data[['date', 'orders']]\nmunich_data.set_index('date', inplace=True)\nmunich_data = munich_data.asfreq('D')\nmunich_data.fillna(method='ffill', inplace=True)\n\nfkr_data = train[train['warehouse'] == 'Frankfurt_1']\nfkr_data = fkr_data[fkr_data['year'] != 2022]\nfkr_data.reset_index(drop=True, inplace=True)\nfkr_data = fkr_data[['date', 'orders']]\nfkr_data.set_index('date', inplace=True)\nfkr_data = fkr_data.asfreq('D')\nfkr_data.fillna(method='ffill', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T13:27:39.770738Z","iopub.execute_input":"2024-08-02T13:27:39.771605Z","iopub.status.idle":"2024-08-02T13:27:39.830163Z","shell.execute_reply.started":"2024-08-02T13:27:39.771574Z","shell.execute_reply":"2024-08-02T13:27:39.829421Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf","metadata":{"execution":{"iopub.status.busy":"2024-08-02T13:30:23.302938Z","iopub.execute_input":"2024-08-02T13:30:23.303317Z","iopub.status.idle":"2024-08-02T13:30:23.307625Z","shell.execute_reply.started":"2024-08-02T13:30:23.303287Z","shell.execute_reply":"2024-08-02T13:30:23.306681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_acf_pacf(data, title):\n    fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n    plot_acf(data, lags=30, ax=axes[0])\n    axes[0].set_title(f'{title} - ACF', fontsize=15)\n    plot_pacf(data, lags=30, ax=axes[1])\n    axes[1].set_title(f'{title} - PACF', fontsize=15)\n    plt.tight_layout()\n    plt.show()\n\ndef make_stationary(data):\n    result = adfuller(data)\n    if result[1] > 0.05:\n        data = data.diff().dropna() #detrend\n    return data\n\nwarehouse_data = {\n    'Brno_1': brno_data,\n    'Prague_1': pr1_data,\n    'Prague_2': pr2_data,\n    'Prague_3': pr3_data,\n    'Budapest_1': bdp_data,\n    'Munich_1': munich_data,\n    'Frankfurt_1': fkr_data\n}\n\n\nfor warehouse, data in warehouse_data.items():\n    orders_data = data['orders'].copy()\n    stationary_orders_data = make_stationary(orders_data)\n    plot_acf_pacf(stationary_orders_data, warehouse)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T13:30:23.482890Z","iopub.execute_input":"2024-08-02T13:30:23.483645Z","iopub.status.idle":"2024-08-02T13:30:28.169362Z","shell.execute_reply.started":"2024-08-02T13:30:23.483614Z","shell.execute_reply":"2024-08-02T13:30:28.168388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notes\n\n* None of the time series are random walk processes, which is expected.\n* Weekly seasonality is very strong\n* The pattern described by the ACF plots suggest that an autoregressive process is at play\n* Negative coefficients and significant autocorrelation at large lags imply that these series are not moving average processes.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}